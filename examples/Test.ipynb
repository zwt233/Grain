{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1]: Upload cora dataset.\n",
      "| # of nodes : 2708\n",
      "| # of edges : 5278.0\n",
      "| # of features : 1433\n",
      "| # of clases   : 7\n",
      "| # of train set : 140\n",
      "| # of val set   : 500\n",
      "| # of test set  : 1000\n",
      "GRAIN(NN-D) node selection start\n",
      "GRAIN(NN-D) node selection finished\n",
      "GRAIN(ball-D) node selection start\n",
      "GRAIN(ball-D) node selection finished\n",
      "xxxxxxxxxx GRAIN(NN-D) Evaluation begin  xxxxxxxxxx\n",
      "0.829 0.833\n",
      "0.8240000000000001 0.825\n",
      "0.819 0.817\n",
      "0.815 0.809\n",
      "0.81 0.799\n",
      "0.808 0.81\n",
      "0.806 0.812\n",
      "0.804 0.807\n",
      "0.802 0.81\n",
      "0.8 0.804\n",
      "xxxxxxxxxx GRAIN(NN-D) Evaluation end  xxxxxxxxxx\n",
      "xxxxxxxxxx GRAIN(ball-D) Evaluation begin  xxxxxxxxxx\n",
      "0.838 0.842\n",
      "0.834 0.821\n",
      "0.8240000000000001 0.823\n",
      "0.822 0.817\n",
      "0.8200000000000001 0.824\n",
      "0.818 0.811\n",
      "0.816 0.817\n",
      "0.814 0.805\n",
      "0.812 0.823\n",
      "0.81 0.788\n",
      "xxxxxxxxxx GRAIN(ball-D) Evaluation end  xxxxxxxxxx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from scipy.sparse import csgraph\n",
    "from torch.backends import cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "from utils import *\n",
    "from graphConvolution import *\n",
    "\n",
    "#hyperparameters\n",
    "num_node = 2708\n",
    "num_coreset = 140\n",
    "hidden_size = 128\n",
    "dmax = np.ones(num_node)\n",
    "gamma = 1\n",
    "radium = 0.05\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid,bias=True)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass,bias=True)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x\n",
    "   \n",
    "def train(epoch, model,record):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features_GCN, adj)\n",
    "    loss_train = F.cross_entropy(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    output = model(features_GCN, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    record[acc_val.item()] = acc_test.item()\n",
    "    \n",
    "    \n",
    "def get_receptive_fields_dense(cur_neighbors, selected_node, weighted_score): \n",
    "    receptive_vector=((cur_neighbors+adj_matrix2[selected_node])!=0)+0\n",
    "    count=weighted_score.dot(receptive_vector)\n",
    "    return count\n",
    "\n",
    "def get_current_neighbors_dense(cur_nodes):\n",
    "    if np.array(cur_nodes).shape[0]==0:\n",
    "        return 0\n",
    "    neighbors=(adj_matrix2[list(cur_nodes)].sum(axis=0)!=0)+0\n",
    "    return neighbors\n",
    "\n",
    "def get_max_nnd_node_dense(idx_used,high_score_nodes,min_distance): \n",
    "    max_receptive_node = 0\n",
    "    max_total_score = 0\n",
    "    cur_neighbors=get_current_neighbors_dense(idx_used)\n",
    "    for node in high_score_nodes:\n",
    "        receptive_field=get_receptive_fields_dense(cur_neighbors,node,num_ones)\n",
    "        node_distance = distance_aax[node,:]\n",
    "        node_distance = np.where(node_distance<min_distance,node_distance,min_distance)\n",
    "        node_distance = dmax - node_distance\n",
    "        distance_score = node_distance.dot(num_ones)\n",
    "        total_score = receptive_field/num_node+gamma*distance_score/num_node\n",
    "        if total_score > max_total_score:\n",
    "            max_total_score = total_score\n",
    "            max_receptive_node = node        \n",
    "    return max_receptive_node\n",
    "\n",
    "def aug_normalized_adjacency(adj):\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    row_sum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(row_sum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "\n",
    "def compute_distance(_i,_j):\n",
    "    return la.norm(features_aax[_i,:]-features_aax[_j,:])\n",
    "#read dataset\n",
    "adj, features, labels, idx_train, idx_val, idx_test = load_data(dataset=\"cora\")\n",
    "features_GCN = copy.deepcopy(features)\n",
    "features_GCN = torch.FloatTensor(features_GCN).cuda()\n",
    "\n",
    "num_zeros = np.zeros(num_node)\n",
    "num_ones = np.ones(num_node)\n",
    "idx_val = list(idx_val.cpu())\n",
    "idx_test = list(idx_test.cpu())\n",
    "idx_avaliable = list()\n",
    "for i in range(num_node):\n",
    "    if i not in idx_val and i not in idx_test:\n",
    "        idx_avaliable.append(i)\n",
    "\n",
    "#compute normalized distance\n",
    "adj = aug_normalized_adjacency(adj)\n",
    "adj_matrix = torch.FloatTensor(adj.todense()).cuda()\n",
    "adj_matrix2 = torch.mm(adj_matrix,adj_matrix).cuda()\n",
    "features = features.cuda()\n",
    "features_aax = np.array(torch.mm(adj_matrix2,features).cpu())\n",
    "adj_matrix2 = np.array(adj_matrix2.cpu())\n",
    "\n",
    "distance_aax = np.zeros((num_node,num_node))\n",
    "for i in range(num_node-1):\n",
    "    for j in range(i+1,num_node):\n",
    "        distance_aax[i][j] = compute_distance(i,j)\n",
    "        distance_aax[j][i] = distance_aax[i][j]\n",
    "dis_range = np.max(distance_aax) - np.min(distance_aax)\n",
    "distance_aax = (distance_aax - np.min(distance_aax))/dis_range\n",
    "\n",
    "print('GRAIN(NN-D) node selection start')\n",
    "#chooose node\n",
    "min_distance = np.ones(num_node)\n",
    "idx_train_nnd = []\n",
    "idx_avaliable_temp = copy.deepcopy(idx_avaliable)\n",
    "count = 0\n",
    "while True:\n",
    "    max_reception_node = get_max_nnd_node_dense(idx_train_nnd,idx_avaliable_temp,min_distance) \n",
    "    idx_train_nnd.append(max_reception_node) \n",
    "    idx_avaliable.remove(max_reception_node)\n",
    "    idx_avaliable_temp.remove(max_reception_node)\n",
    "    count += 1\n",
    "    max_node_distance = distance_aax[max_reception_node,:]\n",
    "    min_distance = np.where(min_distance<max_node_distance,min_distance,max_node_distance)\n",
    "    if count >= num_coreset:\n",
    "        break\n",
    "\n",
    "print('GRAIN(NN-D) node selection finished')\n",
    "\n",
    "print('GRAIN(ball-D) node selection start')\n",
    "balls = np.zeros((num_node,num_node))\n",
    "balls_dict=dict()\n",
    "covered_balls = set()\n",
    "for i in range(num_node):\n",
    "    for j in range(num_node):\n",
    "        if distance_aax[i][j] <= radium:\n",
    "            balls[i][j]=1\n",
    "\n",
    "idx_avaliable_tmp = copy.deepcopy(idx_avaliable)\n",
    "for node in idx_avaliable_tmp:\n",
    "    neighbors_tmp = get_current_neighbors_dense([node])\n",
    "    neighbors_tmp = neighbors_tmp[:,np.newaxis]\n",
    "    dot_result = np.matmul(balls,neighbors_tmp).T\n",
    "    tmp_set = set()\n",
    "    for i in range(num_node):\n",
    "        if dot_result[0,i]!=0:\n",
    "            tmp_set.add(i)\n",
    "    balls_dict[node]=tmp_set\n",
    "\n",
    "#choose the node\n",
    "count = 0\n",
    "idx_train_balld = []\n",
    "while True: \n",
    "    ball_num_max = 0\n",
    "    node_max = 0\n",
    "    for node in idx_avaliable_tmp:\n",
    "        tmp_num = len(covered_balls.union(balls_dict[node]))\n",
    "        if tmp_num > ball_num_max:\n",
    "            ball_num_max = tmp_num\n",
    "            node_max = node\n",
    "    res_ball_num = num_node - ball_num_max\n",
    "    count+=1\n",
    "    idx_train_balld.append(node_max)\n",
    "    idx_avaliable_tmp.remove(node_max)\n",
    "    covered_balls = covered_balls.union(balls_dict[node_max])\n",
    "    if count >= num_coreset or res_ball_num==0:\n",
    "        break\n",
    "\n",
    "print('GRAIN(ball-D) node selection finished')\n",
    "\n",
    "\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj).float().cuda()\n",
    "labels = labels.cuda()\n",
    "idx_val = torch.LongTensor(idx_val).cuda()\n",
    "idx_test = torch.LongTensor(idx_test).cuda()\n",
    "\n",
    "print('xxxxxxxxxx GRAIN(NN-D) Evaluation begin  xxxxxxxxxx')\n",
    "idx_train = torch.LongTensor(idx_train_nnd).cuda()\n",
    "record = {}\n",
    "model = GCN(nfeat=features_GCN.shape[1],\n",
    "        nhid=hidden_size,\n",
    "        nclass=labels.max().item() + 1,\n",
    "        dropout=0.85)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.05, weight_decay=5e-4)\n",
    "for epoch in range(400):\n",
    "    train(epoch,model,record)\n",
    "\n",
    "bit_list = sorted(record.keys())\n",
    "bit_list.reverse()\n",
    "for key in bit_list[:10]:\n",
    "    value = record[key]\n",
    "    print(key,value)\n",
    "print('xxxxxxxxxx GRAIN(NN-D) Evaluation end  xxxxxxxxxx')\n",
    "\n",
    "\n",
    "print('xxxxxxxxxx GRAIN(ball-D) Evaluation begin  xxxxxxxxxx')\n",
    "idx_train = torch.LongTensor(idx_train_balld).cuda()\n",
    "record = {}\n",
    "model = GCN(nfeat=features_GCN.shape[1],\n",
    "        nhid=hidden_size,\n",
    "        nclass=labels.max().item() + 1,\n",
    "        dropout=0.85)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.05, weight_decay=5e-4)\n",
    "for epoch in range(400):\n",
    "    train(epoch,model,record)\n",
    "\n",
    "bit_list = sorted(record.keys())\n",
    "bit_list.reverse()\n",
    "for key in bit_list[:10]:\n",
    "    value = record[key]\n",
    "    print(key,value)\n",
    "print('xxxxxxxxxx GRAIN(ball-D) Evaluation end  xxxxxxxxxx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
